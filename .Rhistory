# when data is a data.frame, but we need a transaction-style,
# in order for the arules package to work:
# we transform it into the required format
library(arules)  # must do this for the next line to work !
tdata <- as(df, "transactions")
#method 1 of clustering: eclat algorithm
eclat_res <- inspect(eclat(tdata, parameter = list(supp=0.07, maxlen=15)))
eclat_plot <- itemFrequencyPlot(tdata, topN=10, type="absolute", main="item freguency")
summary_data <- summary(tdata)
eclat_summary <- summary(eclat(tdata, parameter = list(supp=0.07, maxlen=15)))
#method 2 of clustering: apriori algorithm
rules <- apriori(tdata)
apriori_summary <- summary(rules)
apriori_res <- inspect(rules)
#look at subsets
#r1 <- subset(rules, subset=rhs %in% "Species=setosa")
#inspect(head(r1, n=3, by="confidence"))
clusters_found <- list(eclat_res, apriori_res, eclat_plot)
return(clusters_found)
}
view_assoc(df = datasets::iris)
iris[1:50,]$Petal.Length
LaplacesDemon::KLD(px=df1,py=df2)
df1 = iris[1:50,]$Petal.Length
df2= iris[101:150,]$Petal.Length
df1 = iris[1:50,]$Petal.Length;  df2= iris[101:150,]$Petal.Length
LaplacesDemon::KLD(px=df1,py=df2)
rep( 1:2, c(length(px=df1), length(py=df2)) )
c(length(px=df1), length(py=df2))
length(px=df1)
rep( 1:2, c(length(df1), length(df2)) )
sm::sm.density.compare(c(px,py), group = group.index, model = "equal")
sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot will be generated automatically
group.index <- rep( 1:2, c(length(df1), length(df2)) )
## collect data toge ther and use sm.density.compare()
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot will be generated automatically
check_assumptions_data <- function(df1, df2) {
print("the assumption about data to be checked: distributional difference")
#---- check if df1 and df2 come from different distributions:
# use resampling methods and/or KL measure
#continuous
kld <- LaplacesDemon::KLD(px=df1,py=df2)
#or resampling based tests
#sm::density.compare
#Bowman, A.W. and Azzalini, A. (1997). Applied Smoothing Techniques for Data Analysis: the Kernel Approach with S-Plus Illustrations. Oxford University Press, Oxford.
# where two groups, each of length: length(px), length(py) need to be compared
group.index <- rep( 1:2, c(length(df1), length(df2)) )
## collect data toge ther and use sm.density.compare()
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot will be generated automatically
return(den)
}
check_assumptions_test <- function(df, test_name) {
#--------------
print("the test assumptions about data to be checked")
}
check_assumptions_model <- function(model_name) {
#---------------
print("the model assumptions about data to be checked")
}
check_assumptions_data(df1 = iris[1:50,]$Petal.Length df2= iris[101:150,]$Petal.Length)
check_assumptions_data(df1 = iris[1:50,]$Petal.Length, df2= iris[101:150,]$Petal.Length)
kld
df1 = iris[1:50,]$Petal.Length
df2= iris[101:150,]$Petal.Length
LaplacesDemon::KLD(px=df1,py=df2)
LaplacesDemon::KLD(px=df1,py=df2)
group.index <- rep( 1:2, c(length(df1), length(df2)) )
## collect data toge ther and use sm.density.compare()
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot will be generated automatically
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot is
den
check_assumptions_data <- function(df1, df2) {
print("the assumption about data to be checked: distributional difference")
#---- check if df1 and df2 come from different distributions:
# use resampling methods and/or KL measure
#continuous
kld <- LaplacesDemon::KLD(px=df1,py=df2)
#or resampling based tests
#sm::density.compare
#Bowman, A.W. and Azzalini, A. (1997). Applied Smoothing Techniques for Data Analysis: the Kernel Approach with S-Plus Illustrations. Oxford University Press, Oxford.
# where two groups, each of length: length(px), length(py) need to be compared
group.index <- rep( 1:2, c(length(df1), length(df2)) )
## collect data toge ther and use sm.density.compare()
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot is generated automatically by this function
return(den, kld)
}
check_assumptions_test <- function(df, test_name) {
#--------------
print("the test assumptions about data to be checked")
}
check_assumptions_model <- function(model_name) {
#---------------
print("the model assumptions about data to be checked")
}
check_assumptions_data(df1 = iris[1:50,]$Petal.Length, df2= iris[101:150,]$Petal.Length)
check_assumptions_data <- function(df1, df2) {
print("the assumption about data to be checked: distributional difference")
#---- check if df1 and df2 come from different distributions:
# use resampling methods and/or KL measure
#continuous
kld <- LaplacesDemon::KLD(px=df1,py=df2)
#or resampling based tests
#sm::density.compare
#Bowman, A.W. and Azzalini, A. (1997). Applied Smoothing Techniques for Data Analysis: the Kernel Approach with S-Plus Illustrations. Oxford University Press, Oxford.
# where two groups, each of length: length(px), length(py) need to be compared
group.index <- rep( 1:2, c(length(df1), length(df2)) )
## collect data toge ther and use sm.density.compare()
den <- sm::sm.density.compare(c(px=df1,py=df2), group = group.index, model = "equal")
## plot is generated automatically by this function
compared <- list(den, kld)
return()
}
check_assumptions_test <- function(df, test_name) {
#--------------
print("the test assumptions about data to be checked")
}
check_assumptions_model <- function(model_name) {
#---------------
print("the model assumptions about data to be checked")
}
check_assumptions_data(df1 = iris[1:50,]$Petal.Length, df2= iris[101:150,]$Petal.Length)
#'
check_assumptions_data(df1 = iris[1:50,]$Petal.Length, df2= iris[101:150,]$Petal.Length)
x <- c(1:30); y <- x^2+rnorm(30,0,2)
model_a= lm(y~x)
print(raintest(model_a, order.by="mahalanobis"))
print(lmtest::raintest(model_a, order.by="mahalanobis"))
dwtest(model_a)
lmtest::dwtest(model_a)
hist(residuals(model_a))
#---------- normality test for residuals of models
print(jarque.bera.test(residuals(model_a)))
print(tsoutliers::jarque.bera.test(residuals(model_a)))
install.packages("tsoutliers")
#---------- normality test for residuals of models
print(tsoutliers::jarque.bera.test(residuals(model_a)))
library(tsoutliers)
print(jarque.bera.test(residuals(model_a)))
library(tseries)
print(jarque.bera.test(residuals(model_a)))
print(tseries::jarque.bera.test(residuals(model_a)))
vsgoftest::vs.test(residual(model_a), dnorm)
install.packages(vsgoftest)
install.packages("vsgoftest")
raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)
vsgoftest::vs.test(residual(model_a), dnorm)
vsgoftest::vs.test(x=residual(model_a), densfun=dnorm)
vsgoftest::vs.test(x=residual(model_a), densfun="dnorm")
vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
durbin_watson_testing <- lmtest::dwtest(model_a)
durbin_watson_testing
jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
print(vs_goodness_of_fit_testing)
histogram_residuals <- hist(residuals(model_a))
histogram_residuals
histogram_residuals <- plot(hist(residuals(model_a)))
histogram_residuals
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing,
hist(residuals(model_a)))
out_model_glm
plot_resid_distr <- hist(residuals(model_a))
plot_resid_distr
plot(plot_resid_distr)
plot(plot_resid_distr)
plot(plot_resid_distr)
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing,
plot_resid_distr)
}
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing,
plot_resid_distr)
out_model_glm
print(Box.test (residuals(model_a), lag = 1, type="Ljung"))
portmanteau_testing_ts_resid <- Box.test (residuals(model_a), lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
#----------- portmanteau tests for model r
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
print(kpss.test(residuals(model_a)))  #------- stat
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
dev.new()
par(mfrow=c(2,1))
acf(residuals(model_a))  # -------- estimate of autocorrelation fct,uni/multi-variate
pacf(residuals(model_a)) # -------- estimate of partial autocorrelation fct, uni/multi-variate
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
kpss_testing <- kpss.test(residuals(model_a))
print(kpss_testing)  #------- stationarity
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
out_model_ts
rev_model <- function( mts, model_a, ...) {
if (mts==m)
#model is regression type or glm
{
raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)
#------------------------ rainbow test for linearity
### J.M. Utts (1982), The Rainbow Test for Lack of Fit in Regression.
### Communications in Statistics -- Theory and Methods 11,2801--2815.
durbin_watson_testing <- lmtest::dwtest(model_a)
#--------------Durbin-Watson-Test on autocorrelation of disturbances
plot_resid_distr <- hist(residuals(model_a))
plot(plot_resid_distr)
#---------- normality test for residuals of models
jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)
##a GOF test based on an entropy measure
#Justine Lequesne, Philippe Regnault. vsgoftest:
#An R Package for Goodness-of-Fit Testing Based on
#Kullback-Leibler Divergence. 2018. ￿hal-01816063
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
print(vs_goodness_of_fit_testing)
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing)
}
else
# time series model
{
# ts models ***
#---- portmanteau tests for model residuals, ts models
portmanteau_testing_ts_resid <- Box.test (residuals(model_a), lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
# visualization, model diagnostics
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
# visualization, residuals diagnostics
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
kpss_testing <- kpss.test(residuals(model_a))
print(kpss_testing)  #------- stationarity
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
#visualization: (auto-) correlation
dev.new()
par(mfrow=c(2,1))
acf(residuals(model_a))  # -------- estimate of autocorrelation fct,uni/multi-variate
pacf(residuals(model_a)) # -------- estimate of partial autocorrelation fct, uni/multi-variate
}
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
return(list(out_model_glm, out_model_ts))
}
x <- c(1:30); y <- x^2+rnorm(30,0,2)
rev_model(mts=m, model_a= lm(y~x))
rev_model <- function( mts, model_a, ...) {
if (mts== "m")
#model is regression type or glm
{
raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)
#------------------------ rainbow test for linearity
### J.M. Utts (1982), The Rainbow Test for Lack of Fit in Regression.
### Communications in Statistics -- Theory and Methods 11,2801--2815.
durbin_watson_testing <- lmtest::dwtest(model_a)
#--------------Durbin-Watson-Test on autocorrelation of disturbances
plot_resid_distr <- hist(residuals(model_a))
plot(plot_resid_distr)
#---------- normality test for residuals of models
jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)
##a GOF test based on an entropy measure
#Justine Lequesne, Philippe Regnault. vsgoftest:
#An R Package for Goodness-of-Fit Testing Based on
#Kullback-Leibler Divergence. 2018. ￿hal-01816063
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
print(vs_goodness_of_fit_testing)
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing)
}
else
# time series model
{
# ts models ***
#---- portmanteau tests for model residuals, ts models
portmanteau_testing_ts_resid <- Box.test (residuals(model_a), lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
# visualization, model diagnostics
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
# visualization, residuals diagnostics
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
kpss_testing <- kpss.test(residuals(model_a))
print(kpss_testing)  #------- stationarity
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
#visualization: (auto-) correlation
dev.new()
par(mfrow=c(2,1))
acf(residuals(model_a))  # -------- estimate of autocorrelation fct,uni/multi-variate
pacf(residuals(model_a)) # -------- estimate of partial autocorrelation fct, uni/multi-variate
}
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
return(list(out_model_glm, out_model_ts))
}
x <- c(1:30); y <- x^2+rnorm(30,0,2)
rev_model(mts="m", model_a= lm(y~x))
#model is regression type or glm
rev_model <- function(model_a, ...) {
raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)
#------------------------ rainbow test for linearity
### J.M. Utts (1982), The Rainbow Test for Lack of Fit in Regression.
### Communications in Statistics -- Theory and Methods 11,2801--2815.
durbin_watson_testing <- lmtest::dwtest(model_a)
#--------------Durbin-Watson-Test on autocorrelation of disturbances
plot_resid_distr <- hist(residuals(model_a))
plot(plot_resid_distr)
#---------- normality test for residuals of models
jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)
##a GOF test based on an entropy measure
#Justine Lequesne, Philippe Regnault. vsgoftest:
#An R Package for Goodness-of-Fit Testing Based on
#Kullback-Leibler Divergence. 2018. ￿hal-01816063
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
print(vs_goodness_of_fit_testing)
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing)
return(out_model_glm)
}
#model is a time series model
rev_model_ts <- function(model_a, ...) {
#---- portmanteau tests for model residuals, ts models
portmanteau_testing_ts_resid <- Box.test (residuals(model_a), lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
# visualization, model diagnostics
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
# visualization, residuals diagnostics
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
kpss_testing <- kpss.test(residuals(model_a))
print(kpss_testing)  #------- stationarity
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
#visualization: (auto-) correlation
dev.new()
par(mfrow=c(2,1))
acf(residuals(model_a))  # -------- estimate of autocorrelation fct,uni/multi-variate
pacf(residuals(model_a)) # -------- estimate of partial autocorrelation fct, uni/multi-variate
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
return(out_model_ts)
}
#------- model is regression type or glm ----------------------
rev_model <- function(model_a, ...) {
raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)
#------------------------ rainbow test for linearity
### J.M. Utts (1982), The Rainbow Test for Lack of Fit in Regression.
### Communications in Statistics -- Theory and Methods 11,2801--2815.
durbin_watson_testing <- lmtest::dwtest(model_a)
#--------------Durbin-Watson-Test on autocorrelation of disturbances
plot_resid_distr <- hist(residuals(model_a))
plot(plot_resid_distr)
#---------- normality test for residuals of models
jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)
##a GOF test based on an entropy measure
#Justine Lequesne, Philippe Regnault. vsgoftest:
#An R Package for Goodness-of-Fit Testing Based on
#Kullback-Leibler Divergence. 2018. ￿hal-01816063
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a), densfun="dnorm")
print(vs_goodness_of_fit_testing)
out_model_glm <- list( raintesting, durbin_watson_testing,
jarque_bera_testing,  vs_goodness_of_fit_testing)
return(out_model_glm)
}
#----- model is a time series model ------------------------------
rev_model_ts <- function(model_a, ...) {
#---- portmanteau tests for model residuals, ts models
portmanteau_testing_ts_resid <- Box.test (residuals(model_a), lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
# visualization, model diagnostics
dev.new()
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
# visualization, residuals diagnostics
dev.new()
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)
kpss_testing <- kpss.test(residuals(model_a))
print(kpss_testing)  #------- stationarity
adf_testing <- adf.test(residuals(model_a))
print( adf_testing)  #-------- non-stationarity
#visualization: (auto-) correlation
dev.new()
par(mfrow=c(2,1))
acf(residuals(model_a))  # -------- estimate of autocorrelation fct,uni/multi-variate
pacf(residuals(model_a)) # -------- estimate of partial autocorrelation fct, uni/multi-variate
out_model_ts <- list(portmanteau_testing_ts_resid, kpss_testing,  adf_testing)
return(out_model_ts)
}
x <- c(1:30); y <- x^2+rnorm(30,0,2); model_ex = lm(y~x);
rev_model(model_a= model_ex)
rev_model_ts(model_a=model_ex)
tsuniv = ts(rnorm(1000)
)
tseries::jarque.bera.test(tsuniv)
tseries::kpss.test(tsuniv)
tseries::kpss.test(tsuniv, null = "Trend")
tseries::adf.test(tsuniv)
forecast::Acf(tsuniv)
forecast::Pacf(tsuniv)
tsfeatures::tsfeatures(tsuniv)
rlist_univ <- list(
tseries::jarque.bera.test(tsuniv),
tseries::kpss.test(tsuniv),
tseries::kpss.test(tsuniv, null = "Trend"),
tseries::adf.test(tsuniv),
forecast::Acf(tsuniv),
forecast::Pacf(tsuniv),
tsfeatures::tsfeatures(tsuniv)
)
rlist_univ
forecast::Ccf(tsuniv, cumsum(tsuniv))
tsmultiv = ts(matrix(rnorm(3000),ncol=100),freq=4)
tsmultiv[1,]
tsmultiv
tsmultiv[,1]
forecast::Ccf(tsmultiv[,1], tsmultiv[,5])
tsmultiv = ts(matrix(rnorm(3000),ncol=100),freq=4)
y <- anomalous::tsmeasures(tsmultiv)
y
anomalous::biplot.features(y)
anomalous::anomaly(y)
# all important characteristics of multivar ts in:
all_characteristics <- tsfeatures::tsfeatures(tsmultiv)
all_characteristic
all_characteristics
tsmultiv
head(tsmultiv, 5)
dim(tsmultiv)
length(tsmultiv[1,])
tsm1=tsmultiv_ex[,10]; tsm2 = tsmultiv_ex[,20]
tsmultiv_ex = ts(matrix(rnorm(3000),ncol=100),freq=4)
forecast::Ccf(tsm1, tsmv2)
tsm1=tsmultiv_ex[,10]
tsm2 = tsmultiv_ex[,20]
forecast::Ccf(tsm1, tsm2)
#' univariate ts
rev_ts_univ <- function(tsuniv, ...) {
rlist_univ <- list(
tseries::jarque.bera.test(tsuniv),
tseries::kpss.test(tsuniv),
tseries::kpss.test(tsuniv, null = "Trend"),
tseries::adf.test(tsuniv),
forecast::Acf(tsuniv),
forecast::Pacf(tsuniv),
tsfeatures::tsfeatures(tsuniv)
)
return(rlist)
}
# tapered versions could be done as in Hyndman (2015), Discussion of High-dimensional autocovariance matrices ..."
# forecast::taperedacf(xxxx)
# forecast::taperedpacf(xxxx)
#' multivariate ts
#' using Hyndman´s anomalous and tsfeatures packages --------------
#' https://robjhyndman.com/hyndsight/tscharacteristics/
#'
rev_ts_multiv <- function(tsmultiv, ...) {
y <- anomalous::tsmeasures(tsmultiv)
anomalous::biplot.features(y)
anomalous::anomaly(y)
# all important characteristics of multivar ts in:
all_characteristics <- tsfeatures::tsfeatures(tsmultiv)
## should include also
# cross-correlations of any two series
# ex
# tsm1=tsmultiv_ex[,10]; tsm2 = tsmultiv_ex[,20]
# forecast::Ccf(tsm1, tsm2)
return( all_characteristics)
}
rev_ts_univ(tsuniv = ts(rnorm(1000)));
tsmultiv_ex = ts(matrix(rnorm(3000),ncol=100),freq=4);
rev_ts_multiv(tsmultiv = tsmultiv_ex)
render(view_data(df))
rmarkdown::render(view_data(df))
rmarkdown::render(view_data.R)
}
rmarkdown::render(view_data.R)
rmarkdown::render("view_data.R")
getwd()
rmarkdown::render("rmd_reports/report_ex_1.Rmd")
